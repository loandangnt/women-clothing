{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "path = '/Users/dangloan/Documents/learning_analytics/project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + '3_data/clothing_review/Womens Clothing E-Commerce Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns =['Clothing_ID',\n",
    " 'Age',\n",
    " 'Title',\n",
    " 'Review_Text',\n",
    " 'Rating',\n",
    " 'Recommended_IND',\n",
    " 'Positive_Feedback_Count',\n",
    " 'Division_Name',\n",
    " 'Department_Name',\n",
    " 'Class_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "a = df.groupby('Clothing_ID')['Age'].count().reset_index()\n",
    "b= a.sort_values(by='Age',ascending=False)\n",
    "# b['Age'] = b['Age'].astype(int)\n",
    "b['Clothing_ID'] = b['Clothing_ID'].astype(str)\n",
    "print(b['Age'].dtype)\n",
    "print(b['Clothing_ID'].dtype)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "sns.distplot(a['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A product (Clothing_ID) can receive more than one review. So, analysis per product can be an idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "profile = pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean data\n",
    "#First remove duplicates\n",
    "df[df.duplicated(keep=False)].sort_values(by='Clothing_ID')\n",
    "df.drop_duplicates(keep='first',inplace=True)\n",
    "# df[df['Clothing_ID'] == 862]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = df.groupby('Class_Name').agg({'Rating': ['mean','std','count']}).reset_index()\n",
    "a.columns = ['Class_Name','Rating_mean','Rating_std','Rating_count']\n",
    "a = a[~a['Class_Name'].isin(['Chemises','Casual bottoms','Trend'])]\n",
    "\n",
    "\n",
    "dept_map = df[['Class_Name','Department_Name']]\n",
    "dept_map.drop_duplicates(keep='first', inplace=True)\n",
    "dept_map.dropna(inplace=True)\n",
    "\n",
    "a = pd.merge(a, dept_map, how='left', on='Class_Name')\n",
    "a.sort_values('Rating_std',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# df = px.data.gapminder()\n",
    "\n",
    "fig = px.scatter(a, x=\"Rating_mean\", y=\"Rating_std\",\n",
    "                 size=\"Rating_count\", color=\"Department_Name\",\n",
    "                 hover_name=\"Class_Name\",log_x=True, size_max=80)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Rating Statistics by Class and Department',\n",
    "    xaxis=dict(\n",
    "        title='Average Rating',\n",
    "        gridcolor='white',\n",
    "        type='log',\n",
    "        gridwidth=2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Rating Standard Deviation',\n",
    "        gridcolor='white',\n",
    "        gridwidth=2,\n",
    "    ),\n",
    "    paper_bgcolor='rgb(243, 243, 243)',\n",
    "    plot_bgcolor='rgb(243, 243, 243)',\n",
    ")\n",
    "plotly.offline.plot(fig, filename='rating_stats_by_class_dept.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as py\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "data=[go.Scatter(\n",
    "    x=[1, 2, 3, 4], y=[10, 11, 12, 13],\n",
    "    mode='markers',\n",
    "    marker_size=[40, 60, 80, 100])\n",
    "]\n",
    "\n",
    "\n",
    "py.offline.plot(data, filename='myplot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Load data, define hover text and bubble size\n",
    "# data = px.data.gapminder()\n",
    "# df_2007 = data[data['year']==2007]\n",
    "a = a.sort_values(['Department_Name', 'Class_Name'])\n",
    "\n",
    "hover_text = []\n",
    "bubble_size = []\n",
    "\n",
    "for index, row in a.iterrows():\n",
    "    hover_text.append(('class_name: {Class_Name}<br>'+\n",
    "                      'mean: {Rating_mean}<br>'+\n",
    "                      'std: {Rating_std}<br>'+\n",
    "                      'count: {Rating_count}<br>'\n",
    "                      ).format(Class_Name=row['Class_Name'],\n",
    "                               Rating_mean=row['Rating_mean'],\n",
    "                               Rating_std=row['Rating_std'],\n",
    "                               Rating_count=row['Rating_count']))\n",
    "                                            \n",
    "    bubble_size.append(math.sqrt(row['Rating_count']))\n",
    "\n",
    "a['text'] = hover_text\n",
    "a['size'] = bubble_size\n",
    "sizeref = 2.*max(a['size'])/(100**2)\n",
    "\n",
    "# Dictionary with dataframes for each continent\n",
    "dept_names = a['Department_Name'].drop_duplicates(keep='first').sort_values().tolist()\n",
    "dept_data = {Department_Name:a.query(\"Department_Name == '%s'\" %Department_Name)\n",
    "                              for Department_Name in dept_names}\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "for dept_names, Department_Name in dept_data.items():\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=Department_Name['Rating_mean'], y=Department_Name['Rating_std'],\n",
    "        name=dept_names, text=Department_Name['text'],\n",
    "        marker_size=Department_Name['size'],\n",
    "        ))\n",
    "\n",
    "# Tune marker appearance and layout\n",
    "fig.update_traces(mode='markers', marker=dict(sizemode='area',\n",
    "                                              sizeref=sizeref, line_width=2))\n",
    "fig.update_layout(\n",
    "    title='Rating Statistics by Class and Department',\n",
    "    xaxis=dict(\n",
    "        title='Average Rating',\n",
    "        gridcolor='white',\n",
    "        type='log',\n",
    "        gridwidth=2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Rating Standard Deviation',\n",
    "        gridcolor='white',\n",
    "        gridwidth=2,\n",
    "    ),\n",
    "    paper_bgcolor='rgb(243, 243, 243)',\n",
    "    plot_bgcolor='rgb(243, 243, 243)',\n",
    ")\n",
    "py.offline.plot(fig, filename='myplot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(data=go.Bar(y=[2, 3, 1]))\n",
    "# fig.show()\n",
    "\n",
    "py.offline.plot(data, filename='myplot.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data with wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I would be curious to see what customers like and don't like in the high rating (Layering, Jeans, etc.) and lower-than-average rating (Trend, Dressees, Blouses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore review review title with wordcloud\n",
    "# Start with loading all necessary libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with one review:\n",
    "text = df.Title[4]\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "#wordcloud = WordCloud().generate(text)\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "df1 = df[(df['Rating'] <= 2)]\n",
    "df2 = df[(df['Rating'] == 5)]\n",
    "df3 = df[(df['Rating'] <= 2) & (df['Class_Name'] == 'Blouses')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "text = \" \".join(review for review in df1.Title.astype(str))\n",
    "print (\"There are {} words in the combination of all review.\".format(len(text)))\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update(['nan','cute','wanted','disappointed','disappointing',\n",
    "                  'disappointment','beautiful','love','dress','terrible',\n",
    "                  'good','top','bad','sadly','nice','great','pretty','horrible',\n",
    "                  'super','poor','sad','way','jeans','run','runs','pant'])\n",
    "\n",
    "wordcloud = WordCloud(stopwords=stopwords,\n",
    "                      background_color=\"black\",\n",
    "                     colormap=\"Dark2\").generate(text) ##'Dark2'\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure(figsize=[14,14])\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top words for high rating (1 and 2 Stars)')\n",
    "plt.savefig(path + '/3_data/clothing_review/WdClould_negative_lessthan2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(path + '/3_data/clothing_review/WdClould_negative_lessthan2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "text = \" \".join(review for review in df2['Review_Text'].astype(str))\n",
    "print (\"There are {} words in the combination of all review.\".format(len(text)))\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update(['nan','cute','wanted','disappointed','disappointing',\n",
    "                  'disappointment','beautiful','love','dress','terrible',\n",
    "                  'good','top','bad','sadly','nice','great','pretty','horrible',\n",
    "                  'super','poor','sad','way','jeans','run','runs','pant',\n",
    "                 'really','back','even','much','ordered','wear','one','tried'])\n",
    "\n",
    "wordcloud = WordCloud(stopwords=stopwords,\n",
    "                      background_color=\"black\",\n",
    "                     colormap=\"tab20\").generate(text) ##'Dark2'\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure(figsize=[14,14])\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top words for high rating (5 Stars)')\n",
    "# plt.savefig(path + '/3_data/clothing_review/WdClould_positive_equal5.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "text = \" \".join(review for review in df3['Title'].astype(str))\n",
    "print (\"There are {} words in the combination of all review.\".format(len(text)))\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update(['nan','cute','wanted','disappointed','disappointing',\n",
    "                  'disappointment','beautiful','love','dress','terrible',\n",
    "                  'good','top','bad','nice','great','pretty','horrible',\n",
    "                  'super','poor','sad','way'])\n",
    "\n",
    "wordcloud = WordCloud(stopwords=stopwords,\n",
    "                      background_color=\"black\",\n",
    "                     colormap=\"magma\").generate(text) ##'Dark2'\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure(figsize=[14,14])\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top words for low rating (1 and 2 Stars)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling by Clothing_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I'm trying to see what people talk about in each product, i.e. if they like or dislike(rating average), then what they like/dislike about that product. I use topic modeling using LDA model. An expected result of the model would be that, for clothing id 1001, positive reviews talk most about quality, while negative reviews talk most about price, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For products with low ratings (rating <=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = df[df['Rating'] <=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg['Review_Text'] = df_neg['Review_Text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df_neg.groupby('Clothing_ID')['Review_Text'].apply(lambda x: x.sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_neg[['Clothing_ID', 'Review_Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df2['lang'] = df2['Review_Text'].apply(detect)\n",
    "df2 = df2.loc[df2.lang=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.loc[df2.lang=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a list of stop words and adding custom stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "##Creating a list of custom stopwords\n",
    "my_words = ['way','back','x','bit','JJS','DT','CD','jacket','pants',\n",
    "           'shirt','dress','VBZ','sweater','top','MD','disappointed',\n",
    "            'usually','still','bottom','however','item',\n",
    "            'reason','much','great','definitely','lb','DT','work',\n",
    "            'x','feel','pair','super','skirt','fall','piece','jean','blouse','denim']\n",
    "stop_words = stop_words.union(my_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Review_Text\n",
    "\n",
    "def clean(text):\n",
    "    #Remove punctuations\n",
    "    t = re.sub('[^a-zA-Z]',' ',text)\n",
    "    #Convert to lowercase\n",
    "    t = t.lower()\n",
    "    #Remove tags\n",
    "    t=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",t)\n",
    "    #Remove special characters and digits\n",
    "    t=re.sub(\"(\\\\d|\\\\W)+\",\" \",t)\n",
    "    #Convert to list from string\n",
    "    t = t.split()\n",
    "    #Remove stopwords\n",
    "    t = [word for word in t if not word in stop_words]\n",
    "    \n",
    "    \n",
    "    t = \" \".join(t)\n",
    "    return t\n",
    "\n",
    "df2['Review_Text_cleaned'] = df2['Review_Text'].apply(lambda x: clean(x))\n",
    "\n",
    "# df2['Review_Text_cleaned1'] =df2['Review_Text_cleaned'].apply(\n",
    "#     lambda l: [item for sublist in l for item in sublist])\n",
    "df2['Review_Text_cleaned'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "df2['Review_Text_sentences'] = df2['Review_Text_cleaned'].apply(sent_tokenize)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "def token_text(text):\n",
    "    return [w_tokenizer.tokenize(w) for w in text]\n",
    "df2['Review_Text_tokenized'] = df2['Review_Text_sentences'].apply(token_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS tagging\n",
    "from nltk import pos_tag\n",
    "\n",
    "# def pos_tag(text):\n",
    "#     return [pos_tag(w) for w in text]\n",
    "# df2['Review_Text_postag'] = df2['Review_Text_sentences'].apply(pos_tag) ## This function results in an \n",
    "#                                                                            ## error \"Maximum recursion\"\n",
    "\n",
    "df2['Review_Text_postag'] = df2['Review_Text_tokenized'].progress_map(lambda sentence:\n",
    "                        [pos_tag(token) for token in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Penn treebank tag to wordnet tag\n",
    "from nltk.corpus import wordnet\n",
    "def penn_to_wn_tags(pos_tag):\n",
    "    if pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "#     elif pos_tag.startswith('R'):\n",
    "#         return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# lemmatize text based on POS tags\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "#     pos_tagged_text = pos_tag_text(text)\n",
    "    lemmatized_tokens = [[wnl.lemmatize(el[0], penn_to_wn_tags(el[1]))\n",
    "                         if penn_to_wn_tags(el[1]) else el[1]\n",
    "                         for el in pos_tagged_text]\n",
    "                         for pos_tagged_text in text]\n",
    "    \n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Review_Text_lemmatized'] = df2['Review_Text_postag'].progress_map(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a list of stop words and adding custom stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "##Creating a list of custom stopwords\n",
    "my_words = ['nan','way','back','x','bit','JJS','DT','CD','VBZ','MD',\n",
    "            'disappointed','usually','still','bottom','however','item',\n",
    "            'reason','much','great','definitely','lb','DT','work',\n",
    "            'x','feel','pair','super','fall','piece','cd',\n",
    "            'seem','md','coat','beautiful','thought','felt',\n",
    "            'sad','ordered','someone','perfect',\n",
    "            'make','wear','love','get','go','order','try','want',\n",
    "            'run','think','see','review','buy','good',\n",
    "            'take','come','give','keep','put','need','say','online',\n",
    "            'bad','nice','cool','dt','rbr','person','purchase',\n",
    "            'jacket','pants','shirt','dress','sweater','top','skirt','jean','blouse','denim']\n",
    "stop_words = stop_words.union(my_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain \n",
    "df2['tokens'] = df2['Review_Text_lemmatized'].map(lambda sentences: list(chain.from_iterable(sentences)))\n",
    "df2['tokens'] = df2['tokens'].map(lambda tokens: [token.lower() for token in tokens if token.isalpha() \n",
    "                                                    and token.lower() not in stop_words and len(token)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get some information of the clothing item from df dataset\n",
    "cat = df_neg[df_neg['Class_Name'] == 'Jeans']\n",
    "df_cat = df2[df2['Clothing_ID'].isin(cat['Clothing_ID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from gensim import corpora, models\n",
    "\n",
    "# list_of_list_of_tokens = [[\"a\",\"b\",\"c\"], [\"d\",\"e\",\"f\"]]\n",
    "# [\"a\",\"b\",\"c\"] are the tokens of document 1, [\"d\",\"e\",\"f\"] are the tokens of document 2...\n",
    "\n",
    "# df_pos['tokens'] = df_pos['Review_Text_lemmatized'].apply(\n",
    "#     lambda x : list(itertools.chain.from_iterable(x)))\n",
    "\n",
    "list_of_list_of_tokens = df2['tokens'].tolist()\n",
    "dictionary_LDA = corpora.Dictionary(list_of_list_of_tokens)\n",
    "dictionary_LDA.filter_extremes(no_below=3)\n",
    "corpus = [dictionary_LDA.doc2bow(list_of_tokens) for list_of_tokens in list_of_list_of_tokens]\n",
    "\n",
    "num_topics = 10\n",
    "%time lda_model = models.LdaModel(corpus, num_topics=num_topics, \\\n",
    "                                  id2word=dictionary_LDA, \\\n",
    "                                  passes=4, alpha=[0.01]*num_topics, \\\n",
    "                                  eta=[0.01]*len(dictionary_LDA.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,topic in lda_model.show_topics(formatted=True, num_topics=num_topics, num_words=40):\n",
    "    print(str(i)+\": \"+ topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model[corpus[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cran.r-project.org/web/packages/LDAvis/vignettes/details.pdf\n",
    "# Here a short legend to explain the vis:\n",
    "# size of bubble: proportional to the proportions of the topics across the N total tokens in the corpus\n",
    "# red bars: estimated number of times a given term was generated by a given topic\n",
    "# blue bars: overall frequency of each term in the corpus\n",
    "# -- Relevance of words is computed with a parameter lambda\n",
    "# -- Lambda optimal value ~0.6 (https://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf)\n",
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "vis = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=corpus, dictionary=dictionary_LDA)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find interesting topics in negative rating reviews (number of topics = 10):\n",
    "##### Topic 10: Price vs quality, delivery time, smell\n",
    "##### Topic 4: Size (top kw: size, small, medium, large, fit)\n",
    "##### Topic 8: Material (top kw: fabric, ichty, thick, hot, seam)\n",
    "##### Topic 2: Color\n",
    "##### Topic 5: Problem related to washing (top kw:wash, dry, hand, shrunk, cold, water, clean, instruction)\n",
    "##### Topic 1: Look in general\n",
    "##### Topic 7: Style/look\n",
    "##### Topic 3: Size and material (thin, sheer)???\n",
    "##### Topic 6: Design (boxy, arm, fit, retailer, hole,seam)???\n",
    "##### Topic 9: Bad tailored details, size???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to disk.\n",
    "temp_file = datapath(\"model\")\n",
    "model.save('lda.lda_model')\n",
    "# Load a potentially pretrained model from disk.\n",
    "lda_model =  models.LdaModel.load('lda.lda_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [lda_model[corpus[i]] for i in range(len(df2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topics_document_to_dataframe(topics_document, num_topics):\n",
    "    res = pd.DataFrame(columns=range(num_topics))\n",
    "    for topic_weight in topics_document:\n",
    "        res.loc[0, topic_weight[0]] = topic_weight[1]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like TF-IDF, create a matrix of topic weighting, with documents as rows and topics as columns\n",
    "document_topic = \\\n",
    "pd.concat([topics_document_to_dataframe(topics_document, num_topics=num_topics) for topics_document in topics]) \\\n",
    "  .reset_index(drop=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dominant_topic = np.argmax(document_topic.values, axis=1)\n",
    "document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "# # Styling\n",
    "# def color_green(val):\n",
    "#     color = 'green' if val > .1 else 'black'\n",
    "#     return 'color: {col}'.format(col=color)\n",
    "\n",
    "# def make_bold(val):\n",
    "#     weight = 700 if val > .1 else 400\n",
    "#     return 'font-weight: {weight}'.format(weight=weight)\n",
    "\n",
    "# # Apply Style\n",
    "# document_topic = document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "document_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=list(range(0,10,1))\n",
    "lda_output = pd.concat([df2[['Clothing_ID','Review_Text']],\n",
    "                       document_topic[['dominant_topic'] + x]],ignore_index=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 =df2[['Clothing_ID','Review_Text']].reset_index()\n",
    "x2=document_topic[['dominant_topic'] + x]\n",
    "y = pd.concat([x1,x2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Find interesting topics in negative rating reviews (number of topics = 10):\n",
    "##### Topic 10: Price vs quality, delivery time, smell\n",
    "##### Topic 4: Size (top kw: size, small, medium, large, fit)\n",
    "##### Topic 8: Material (top kw: fabric, ichty, thick, hot, seam)\n",
    "##### Topic 2: Color\n",
    "##### Topic 5: Problem related to washing (top kw:wash, dry, hand, shrunk, cold, water, clean, instruction)\n",
    "##### Topic 1: Look in general\n",
    "##### Topic 7: Style/look\n",
    "##### Topic 3: Size and material (thin, sheer)???\n",
    "##### Topic 6: Design (boxy, arm, fit, retailer, hole,seam)???\n",
    "##### Topic 9: Bad tailored details, size???\n",
    "\n",
    "### Map to data\n",
    "##### Topic 9: Price vs quality, delivery time, smell\n",
    "##### Topic 3: Size (top kw: size, small, medium, large, fit)\n",
    "##### Topic 7: Material (top kw: fabric, ichty, thick, hot, seam)\n",
    "##### Topic 1: Color\n",
    "##### Topic 4: Problem related to washing (top kw:wash, dry, hand, shrunk, cold, water, clean, instruction)\n",
    "##### Topic 0: Look in general\n",
    "##### Topic 6: Style/look\n",
    "##### Topic 2: Size and material (thin, sheer)???\n",
    "##### Topic 5: Design (boxy, arm, fit, retailer, hole,seam)???\n",
    "##### Topic 8: Size, bad tailored details, ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y[1] >=0.9].sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After going through some sample and verify model result reliability by eyes, it makes sense most of the case. 1 out of 5 case has inappropriate topic allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The topic interpretation I generated seeems to work quite well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I find out that if the second dominant topic is around 0.3, it is worth select it is top topic as well. With that, we can say a review can mention more than 1 major issue of the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's find out how many documents is allocated to each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topic1 = \\\n",
    "pd.concat([topics_document_to_dataframe(topics_document, num_topics=num_topics) for topics_document in topics]) \\\n",
    "  .reset_index(drop=True).fillna(0)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10,5)})\n",
    "document_topic1.idxmax(axis=1).value_counts().plot.bar(color='lightblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Find interesting topics in negative rating reviews (number of topics = 10):\n",
    "##### Topic 10: Price vs quality, delivery time, smell\n",
    "##### Topic 4: Size (top kw: size, small, medium, large, fit)\n",
    "##### Topic 8: Material (top kw: fabric, ichty, thick, hot, seam)\n",
    "##### Topic 2: Color\n",
    "##### Topic 5: Problem related to washing (top kw:wash, dry, hand, shrunk, cold, water, clean, instruction)\n",
    "##### Topic 1: Look in general\n",
    "##### Topic 7: Style/look\n",
    "##### Topic 3: Size and material (thin, sheer)???\n",
    "##### Topic 6: Design (boxy, arm, fit, retailer, hole,seam)???\n",
    "##### Topic 9: Bad tailored details, size???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we can pick documents (reviews) that have very high probability (>=0.85) allocated to a topic. Do it for 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
